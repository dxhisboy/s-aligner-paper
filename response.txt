#############
To Reviewer1:
=============

Q1: The parallel mapping problem is trivial if the reference genome
can be replicated. This paper recognizes this, and partially
replicates the reference and the reads (this would be akin to
partitioning the machien into groups and running a set of reads on
each group with a replicated reference. This is a rather
straightforward approach.

A1: The top-level parallelism that uses replication is certainly
straightforward, but it was included in the paper for completeness.
All three levels of parallelism are critical for performance, albeit
some are more straightforward than others.

-------------

Q2: The other implementation techniques are relatively straightforward
adaptations of existing techniques (including the bitmapped matching
technique).

A2: While there certainly exist similar techniques, we believe the
novelty of the paper lies in the adaptation of these techniques for
the architecture and the application, which are unique.

#############

To Reviewer2:
=============

Q1: What are the main differences of the intra-CG parallelization of
S-Aligner with respect to the TPDS paper (see above)?

A1: While the Sunway architecture and the IBM Cell architecture share
similarities, looking at the detailed architectural characteristics
reveals a number of differences that are important to understand.  One
example is lack of a signaling system on the SW26010 processor which
makes a dynamic task scheduling system not possible (at least not very
easily).  Due to this we have to use a static task scheduling strategy
instead of the task queue implementation.  This leads to a number of
difficulties, which we were able to mitigate by dividing the kernel
into verification and alignment phases, and performing load balancing
between the two phases (Section 3.2 / Figure 8, at the bottom
alignment stage, the intervals are redistributed to each slave
processor, it does not cost much since the athread_spawn has minor
overhead).

-------------

Q2: Section 3.2/Figure 8: Where is the alignment result stored? How do
the SPs synchronize? The box at the bottom of the Slave Processor
Group is not explained.

A2: The alignment result is stored on the file system.  SPs
synchronize using athread_join, just like pthreads or CUDA threads.
The "Generate BP-wise alignment" phase happens only if an interval
passed the verification, while the intervals are redistributed to
other SPs after the athread_join of the verification phase.

-------------

Q3: Section 4.2/Table 1: 

- Is the comparison between these two fair? The Sunway machine has
  more than twice the number of cores (albeit at less than half the
  frequency).

- When changing the size of reads, from 108 to 200 bps, RazerS3 takes
  only a fraction more, whereas the runtime for S-Aligner more than
  doubles. Why is that?

A3: 

- We agree that the comparison is not direct apples-to-apples, but is
  included in the paper as a general guideline of what performance to
  expect from our work.  The x86 processors have a better performance
  at a give clock frequency (larger cache, better branch management,
  pipelining, and other processor front-end features), which makes our
  work even more appealing in comparison.

- RazerS3 does more optimization at the filtration stage while we
  focus on the optimization of verification stage.  The large cost
  difference at #bps = 200 is because we verify a much larger number
  of intervals.  We will clarify this in the paper.
  Also reads with length short than 200 is mostly used in short read
  mappers.

--------------
Q4: Section 4.3/Figure 14: 

- Why start with 13 nodes? 

- Do you consider the final phase of the application that gathers all
  results and writes them to a file?

A4:

- The reference is divided into 12 blocks (limitation of the size of
  the shared memory).  Each node processes one block while the
  remaining node loads reads.

- Yes, except that each process writes to a different file (instead of
  one common file, but each file is compatible to standard SAM/BAM viewer).
  So, there is no gathering of results and writing separate files is 
  more efficient on the Sunway file system.

---------------
To Review3:
===============

Q1: In Sect 4.1, the authors claim that making use of f SPs yielded a
speedup of 118X. That does not seem to match with the numbers in
Fig. 12. Could you explain how that speedup is computed?

A1: By dividing the computation of "MP Myers" and "SP Myers" (800 / 6.8 ~= 118).

---------------

Q2: In Table 1, when #bps is increased (in the last row), RazerS3
execution time is only increased by ~12% while there is a 2.9X
increase for S-Aligner. Does that suggest that S-Aligner is more
sensitive for increased bps values? What is the reason for that?  Can
this affect practical usability of the application (in real world use
cases)?

A2: Please refer to review2's A3.

---------------

Q3: Why scaling stopped at 13,312 nodes number of nodes?

A3: That was the access limit we had on the system.

===============

To The scratchpad size issue mentioned by Review 2:

athread_spawn has a very minor overhead in our implementation (less
than 1% of the computation time) so short task granularities are not a
major concern.  Further, our implementation does not require much
memory since it has O(n) space complexity and O(n^2) time complexity,
32KB of scrathpad memory is enough for a round of computation.
